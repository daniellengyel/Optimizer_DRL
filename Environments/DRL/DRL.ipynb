{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRL \n",
    "\n",
    "DRL is good for demand charge problem since we don't need to incorporate the demand charge cost into every reward. We will incorporate it only into the final states. \n",
    "\n",
    "State:\n",
    "- Last k indoor temperatures of all zones (For now just use current and last)\n",
    "- Last k outdoor temperatures (For now just use current)\n",
    "- Last k actions  (For now just use current)\n",
    "- Time of Month (For demand charge)\n",
    "- Max Consumption so far\n",
    "- Comfortband for t steps into the future\n",
    "- Do not exceed for t steps into the future\n",
    "- occupancy for t steps into the future\n",
    "- price t steps into future\n",
    "\n",
    "Actions: \n",
    "[0,1,2] x num_zones\n",
    "\n",
    "We limit our observation space to one month. disregarding sesonality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add random gaussian noise to all temperatures. Gaussian noise should be distributed according to our uncertainty (historic uncertainty for outdoor temperature for last years etc). \n",
    "- Comfortband/DoNotExceed should be set for one month? \n",
    "- Occupancy should have random noise added i guess. for now just assume schedule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outdoor temperature we want to find distribution:\n",
    "$$P(T_{t+1} | T_{t})$$ so that we can sample from it. \n",
    "For now we could assume:\n",
    "$$P(T_{t+1} | T_{t}) = P(\\delta t_{t+1}) $$\n",
    "which is distributed according to gaussian distribution which has the same variance as our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is this adding to MPC\n",
    "- Easier to make demand charges happen. Do not need to incorporate into objective function at every step. Will be rewarded at the end of month. \n",
    "- Will learn a much longer predictive horizon. \n",
    "- Can use more complex models for predicting indoor temperature. MPC would loose DP possibility if using mmore complex and higher order models. \n",
    "- Could learn underlying effects of occupancy/comfortband which MPC could not catch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from DataManager.DataManager import DataManager\n",
    "from Thermostat import Tstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xbos_services_getter as xsg\n",
    "\n",
    "import gym, ray\n",
    "from gym.spaces import MultiDiscrete, Box, Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-09 16:01:12,317\tINFO node.py:497 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-09_16-01-12_316527_38061/logs.\n",
      "2019-05-09 16:01:12,428\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:61852 to respond...\n",
      "2019-05-09 16:01:12,544\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:47161 to respond...\n",
      "2019-05-09 16:01:12,548\tINFO services.py:806 -- Starting Redis shard with 6.87 GB max memory.\n",
      "2019-05-09 16:01:12,559\tINFO node.py:511 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-09_16-01-12_316527_38061/logs.\n",
      "2019-05-09 16:01:12,563\tINFO services.py:1441 -- Starting the Plasma object store with 10.31 GB memory using /tmp.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.142.38.66',\n",
       " 'redis_address': '10.142.38.66:61852',\n",
       " 'object_store_address': '/tmp/ray/session_2019-05-09_16-01-12_316527_38061/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-05-09_16-01-12_316527_38061/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2019-05-09_16-01-12_316527_38061'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingEnv(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "\n",
    "        self.DataManager = DataManager(env_config[\"building\"], env_config[\"zones\"],\n",
    "                         env_config[\"start\"], env_config[\"end\"], env_config[\"window\"])\n",
    "        \n",
    "        self.start = start\n",
    "        self.unix_start = start.timestamp() * 1e9\n",
    "        self.end = end\n",
    "        self.unix_end = end.timestamp() * 1e9\n",
    "        self.window = window  # timedelta string\n",
    "\n",
    "        self.building = building\n",
    "        self.zones = zones\n",
    "        \n",
    "        self.lambda_val = env_config[\"lambda_val\"]\n",
    "\n",
    "        # assert self.zones == all zones in building. this is because of the thermal model needing other zone temperatures.\n",
    "\n",
    "        self.curr_timestep = 0\n",
    "\n",
    "        self.indoor_starting_temperatures = env_config[\n",
    "            \"indoor_starting_temperatures\"]  # to get starting temperatures [last, current]\n",
    "        self.outdoor_starting_temperature = env_config[\"outdoor_starting_temperature\"]\n",
    "\n",
    "        self.tstats = {}\n",
    "        for iter_zone in self.zones:\n",
    "            self.tstats[iter_zone] = Tstat(self.building, iter_zone,\n",
    "                                           self.indoor_starting_temperatures[iter_zone][\"current\"],\n",
    "                                           last_temperature=self.indoor_starting_temperatures[iter_zone][\"last\"])\n",
    "\n",
    "        assert 60 * 60 % xsg.get_window_in_sec(self.window) == 0  # window divides an hour\n",
    "        assert (self.end - self.start).total_seconds() % xsg.get_window_in_sec(\n",
    "            self.window) == 0  # window divides the timeframe\n",
    "\n",
    "        # the number of timesteps\n",
    "        self.num_timesteps = int((self.end - self.start).total_seconds() / xsg.get_window_in_sec(self.window))\n",
    "\n",
    "        self.unit = env_config[\"unit\"]\n",
    "        assert self.unit == \"F\"\n",
    "\n",
    "        # all zones current and last temperature = 2*num_zones\n",
    "        # building outside temperature -> make a class for how this behaves = 1\n",
    "        # timestep -> do one hot encoding of week, day, hour, window  \\approx 4 + 7 + 24 + 60*60 / window\n",
    "        low_bound = [32] * (2 * len(\n",
    "            self.zones) + 1)  # we could use parametric temperature bounds... for now we will give negative inft reward\n",
    "        high_bound = [100] * (2 * len(self.zones) + 1)  # plus one for building\n",
    "\n",
    "        low_bound += [0] * (self.num_timesteps + 1)  # total timesteps plus the final timestep which wont be executed\n",
    "        high_bound += [1] * (self.num_timesteps + 1)  # total timesteps plus the final timestep which wont be executed\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=np.array(low_bound), high=np.array(high_bound), dtype=np.float32)\n",
    "\n",
    "        self.action_space = MultiDiscrete([3] * len(self.zones))\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.curr_timestep = 0\n",
    "\n",
    "        for iter_zone in self.zones:\n",
    "            self.tstats[iter_zone].reset(self.indoor_starting_temperatures[iter_zone][\"current\"],\n",
    "                                         last_temperature=self.indoor_starting_temperatures[iter_zone][\"last\"])\n",
    "        self.outdoor_temperature = self.outdoor_starting_temperature\n",
    "\n",
    "        return self.create_curr_obs()  # obs\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        self.curr_timestep += 1\n",
    "\n",
    "        # if we reach the end time.\n",
    "        if self.curr_timestep == self.num_timesteps:\n",
    "            return self.create_curr_obs(), 0, True, {}\n",
    "\n",
    "        # find what new temperature would be. use thermal model with uncertainty. use reset if exceeding\n",
    "        # do_not_exceed. can't force it to take a different action anymore.\n",
    "\n",
    "        # update temperatures\n",
    "        for i, iter_zone in enumerate(self.zones):\n",
    "            self.tstats[iter_zone].next_temperature(action[i])\n",
    "            self.outdoor_temperature += np.random.normal()  # TODO we should make a thermostat for the outdoor temperature.\n",
    "\n",
    "        # check that in saftey temperature band\n",
    "        for iter_zone in self.zones:\n",
    "            curr_safety = self.DataManager.do_not_exceed[iter_zone].iloc[self.curr_timestep]\n",
    "            if not (curr_safety[\"t_low\"] <= self.tstats[iter_zone].temperature <= curr_safety[\"t_high\"]):\n",
    "                return self.create_curr_obs(), -float('inf'), True, {}  # TODO do we want to add info?\n",
    "\n",
    "        # get reward by calling discomfort and consumption model ...\n",
    "        reward = self.get_reward(action)\n",
    "\n",
    "        return self.create_curr_obs(), reward, False, {}  # obs, reward, done, info\n",
    "\n",
    "    def get_reward(self, action):\n",
    "        \"\"\"Get the reward for the given action with the current observation parameters.\"\"\"\n",
    "        # get discomfort across edge\n",
    "        discomfort = {}\n",
    "        for iter_zone in self.zones:\n",
    "            # TODO Check this again since we are a timestep ahead and we want average comfortband and average occupancy over the edge.\n",
    "            curr_comfortband = self.DataManager.comfortband[iter_zone].iloc[self.curr_timestep]\n",
    "            curr_occupancy = self.DataManager.occupancy[iter_zone].iloc[self.curr_timestep]\n",
    "            curr_tstat = self.tstats[iter_zone]\n",
    "            average_edge_temperature = (curr_tstat.temperature + curr_tstat.last_temperature) / 2.\n",
    "\n",
    "            discomfort[iter_zone] = self.DataManager.get_discomfort(\n",
    "                self.building, average_edge_temperature,\n",
    "                curr_comfortband[\"t_low\"], curr_comfortband[\"t_high\"],\n",
    "                curr_occupancy)\n",
    "\n",
    "        # Get consumption across edge\n",
    "        price = 1  # self.prices.iloc[root.timestep] TODO also add right unit conversion, and duration\n",
    "        consumption_cost = {self.zones[i]: price * self.DataManager.hvac_consumption[self.zones[i]][action[i]]\n",
    "                            for i in range(len(self.zones))}\n",
    "\n",
    "        cost = ((1 - self.lambda_val) * (sum(consumption_cost.values()))) + (\n",
    "                self.lambda_val * (sum(discomfort.values())))\n",
    "        return -cost\n",
    "\n",
    "    def create_curr_obs(self):\n",
    "        return self._create_obs(self.tstats, self.outdoor_temperature, self.curr_timestep)\n",
    "\n",
    "    def _create_obs(self, tstats, outdoor_temperature, curr_timestep):\n",
    "        obs = np.zeros(self.observation_space.low.shape)\n",
    "        idx = 0\n",
    "        for iter_zone in self.zones:\n",
    "            obs[idx] = tstats[iter_zone].last_temperature\n",
    "            idx += 1\n",
    "            obs[idx] = tstats[iter_zone].temperature\n",
    "            idx += 1\n",
    "        obs[idx] = outdoor_temperature\n",
    "        idx += 1\n",
    "\n",
    "        obs[idx + curr_timestep] = 1\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from ray.rllib.models import FullyConnectedNetwork, Model, ModelCatalog\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import grid_search\n",
    "\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "start = datetime.datetime(year=2019, month=1, day=1).replace(tzinfo=pytz.utc)\n",
    "end = start + datetime.timedelta(days=1)\n",
    "window = \"15m\"\n",
    "building = \"avenal-animal-shelter\"\n",
    "zones = [\"hvac_zone_shelter_corridor\"]\n",
    "indoor_starting_temperatures = {iter_zone: {\"last\": 70, \"current\": 71} for iter_zone in zones}\n",
    "outdoor_starting_temperature = 60\n",
    "unit = \"F\"\n",
    "lambda_val = 0.999\n",
    "\n",
    "config = {\n",
    "    \"start\": start,\n",
    "    \"end\": end,\n",
    "    \"window\": window,\n",
    "    \"building\": building,\n",
    "    \"zones\": zones,\n",
    "    \"indoor_starting_temperatures\": indoor_starting_temperatures,\n",
    "    \"outdoor_starting_temperature\": outdoor_starting_temperature,\n",
    "    \"unit\": unit,\n",
    "    \"lambda_val\": lambda_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = BuildingEnv(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    obs, rew, done, info = e.step([0])\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-09 16:17:39,779\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-05-09 16:17:39,780\tINFO tune.py:223 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/12 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 19.2/34.4 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2/12 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 19.2/34.4 GB\n",
      "Result logdir: /Users/daniellengyel/ray_results/PPO\n",
      "Number of trials: 3 ({'RUNNING': 1, 'PENDING': 2})\n",
      "PENDING trials:\n",
      " - PPO_BuildingEnv_1_lr=0.0001:\tPENDING\n",
      " - PPO_BuildingEnv_2_lr=1e-06:\tPENDING\n",
      "RUNNING trials:\n",
      " - PPO_BuildingEnv_0_lr=0.01:\tRUNNING\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-09 16:17:42,541\tERROR trial_runner.py:497 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daniellengyel/ray/python/ray/tune/trial_runner.py\", line 446, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/daniellengyel/ray/python/ray/tune/ray_trial_executor.py\", line 316, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/Users/daniellengyel/ray/python/ray/worker.py\", line 2197, in get\n",
      "    raise value\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_PPOTrainer:train()\u001b[39m (pid=38091, host=Daniels-MacBook-Pro-4.local)\n",
      "  File \"pyarrow/serialization.pxi\", line 458, in pyarrow.lib.deserialize\n",
      "  File \"pyarrow/serialization.pxi\", line 421, in pyarrow.lib.deserialize_from\n",
      "  File \"pyarrow/serialization.pxi\", line 272, in pyarrow.lib.SerializedPyObject.deserialize\n",
      "  File \"pyarrow/serialization.pxi\", line 171, in pyarrow.lib.SerializationContext._deserialize_callback\n",
      "ModuleNotFoundError: No module named 'Thermostat'\n",
      "\n",
      "2019-05-09 16:17:42,544\tINFO ray_trial_executor.py:180 -- Destroying actor for trial PPO_BuildingEnv_0_lr=0.01. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2019-05-09 16:17:42,580\tERROR trial_runner.py:497 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daniellengyel/ray/python/ray/tune/trial_runner.py\", line 446, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/daniellengyel/ray/python/ray/tune/ray_trial_executor.py\", line 316, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/Users/daniellengyel/ray/python/ray/worker.py\", line 2197, in get\n",
      "    raise value\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_PPOTrainer:train()\u001b[39m (pid=38084, host=Daniels-MacBook-Pro-4.local)\n",
      "  File \"pyarrow/serialization.pxi\", line 458, in pyarrow.lib.deserialize\n",
      "  File \"pyarrow/serialization.pxi\", line 421, in pyarrow.lib.deserialize_from\n",
      "  File \"pyarrow/serialization.pxi\", line 272, in pyarrow.lib.SerializedPyObject.deserialize\n",
      "  File \"pyarrow/serialization.pxi\", line 171, in pyarrow.lib.SerializationContext._deserialize_callback\n",
      "ModuleNotFoundError: No module named 'Thermostat'\n",
      "\n",
      "2019-05-09 16:17:42,583\tINFO ray_trial_executor.py:180 -- Destroying actor for trial PPO_BuildingEnv_1_lr=0.0001. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2019-05-09 16:17:42,613\tERROR trial_runner.py:497 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daniellengyel/ray/python/ray/tune/trial_runner.py\", line 446, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/daniellengyel/ray/python/ray/tune/ray_trial_executor.py\", line 316, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/Users/daniellengyel/ray/python/ray/worker.py\", line 2197, in get\n",
      "    raise value\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_PPOTrainer:train()\u001b[39m (pid=38089, host=Daniels-MacBook-Pro-4.local)\n",
      "  File \"pyarrow/serialization.pxi\", line 458, in pyarrow.lib.deserialize\n",
      "  File \"pyarrow/serialization.pxi\", line 421, in pyarrow.lib.deserialize_from\n",
      "  File \"pyarrow/serialization.pxi\", line 272, in pyarrow.lib.SerializedPyObject.deserialize\n",
      "  File \"pyarrow/serialization.pxi\", line 171, in pyarrow.lib.SerializationContext._deserialize_callback\n",
      "ModuleNotFoundError: No module named 'Thermostat'\n",
      "\n",
      "2019-05-09 16:17:42,616\tINFO ray_trial_executor.py:180 -- Destroying actor for trial PPO_BuildingEnv_2_lr=1e-06. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/12 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 19.5/34.4 GB\n",
      "Result logdir: /Users/daniellengyel/ray_results/PPO\n",
      "Number of trials: 3 ({'ERROR': 3})\n",
      "ERROR trials:\n",
      " - PPO_BuildingEnv_0_lr=0.01:\tERROR, 1 failures: /Users/daniellengyel/ray_results/PPO/PPO_BuildingEnv_0_lr=0.01_2019-05-09_16-17-39z5dnbmm7/error_2019-05-09_16-17-42.txt\n",
      " - PPO_BuildingEnv_1_lr=0.0001:\tERROR, 1 failures: /Users/daniellengyel/ray_results/PPO/PPO_BuildingEnv_1_lr=0.0001_2019-05-09_16-17-39ggww599p/error_2019-05-09_16-17-42.txt\n",
      " - PPO_BuildingEnv_2_lr=1e-06:\tERROR, 1 failures: /Users/daniellengyel/ray_results/PPO/PPO_BuildingEnv_2_lr=1e-06_2019-05-09_16-17-39_37fbxe0/error_2019-05-09_16-17-42.txt\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_BuildingEnv_0_lr=0.01, PPO_BuildingEnv_1_lr=0.0001, PPO_BuildingEnv_2_lr=1e-06])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-41bf7d35f58b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# try different lrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"num_workers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;34m\"env_config\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     },\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;32m~/ray/python/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_function, checkpoint_freq, checkpoint_at_end, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_BuildingEnv_0_lr=0.01, PPO_BuildingEnv_1_lr=0.0001, PPO_BuildingEnv_2_lr=1e-06])"
     ]
    }
   ],
   "source": [
    "# Can also register the env creator function explicitly with:\n",
    "# register_env(\"corridor\", lambda config: SimpleCorridor(config))\n",
    "# ModelCatalog.register_custom_model(\"my_model\", CustomModel)\n",
    "tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\n",
    "        \"timesteps_total\": 10000,\n",
    "    },\n",
    "    config={\n",
    "        \"env\": BuildingEnv,  # or \"corridor\" if registered above\n",
    "        \"lr\": grid_search([1e-2, 1e-4, 1e-6]),  # try different lrs\n",
    "        \"num_workers\": 1,  # parallelism\n",
    "        \"env_config\": config,\n",
    "    },\n",
    ")\n",
    "# e = BuildingEnv(config)\n",
    "# print(e.step([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task: Write a function that takes a positive integer n as input and does\n",
    "# 1) pick positive integer n\n",
    "# 2) print number\n",
    "# 3) subtracts by one\n",
    "# 4) repeats from 2) until n != 0 \n",
    "# and return length of sequence printed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# task: Write a function that takes a positive integer n as input and does\n",
    "# 1) pick positive integer n\n",
    "# 2) if even: prints\n",
    "# 3) odd: does nothing\n",
    "# 4) subtracts by one\n",
    "# 5) repeats until n != 0 \n",
    "# and return length of sequence printed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countdown(n):\n",
    "    counter = 0 \n",
    "    while n > 0:\n",
    "        if n % 2 == 0:\n",
    "            print(n)\n",
    "            counter += 1\n",
    "        else:\n",
    "            pass\n",
    "        n -= 1\n",
    "    \n",
    "    return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "8\n",
      "6\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "countdown(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv-dr3)\n",
   "language": "python",
   "name": "venv-dr3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
